# Задание
### Массовый поиск подстрок
**Язык:** C++ или Python  
**Входные данные:** матрицы строк с различными размерностями  
**Выходные данные:** время вычисления на CPU и GPU, отчет о совпадении/отличии результатов  

# Описание проделанной работы
Данная лабораторная работа была выполнена на языке Python в Google Collab.

В данной лабораторной работе был проведен эксперимент по сравнению времени выполнения алгоритма на CPU и GPU с использованием CUDA для поиска подстрок в матрицах с различными разрешениями.

**CPU:** функция `mass_search_CPU` выполняет поиск подстрок, в каждом цикле она ищет элементы в N[i], которые совпадают с элементом в H[j], и при совпадении уменьшает соответствующее значение в матрице R.

**GPU:** функция `mass_search_GPU` аналогична `mass_search_CPU` и реализована с использованием CUDA для параллельного выполнения на GPU. Каждый поток обрабатывает отдельную пару индексов и также ищет совпадения в подстроках. Используется декорирование `@cuda.jit` для компиляции функции в CUDA-ядро. Измерения проводились на размерностях `GridDim (8,8)` и `BlockDim(16,16)`. Использовалась библиотека numba.

Эксперимент проводится на случайно сгенерированных данных, и результаты времени выполнения сравниваются между CPU и GPU для разных размеров данных. Для каждой размерности программа выполняет несколько запусков для получения усредненных значений времени выполнения, которые можно увидеть в таблице ниже.

# Анализ результатов эксперимента
В таблице ниже представлены результаты измерений времени выполнения на CPU и GPU для различных размеров данных, а также ускорение GPU относительно CPU и результат проверки на совпадение вычислений.

| Размер данных | Время на CPU (среднее) | Время на GPU (среднее) | Ускорение (CPU/GPU) | Результаты совпадают |
|----------------|------------------------|------------------------|---------------------|----------------------|
| 160            | 0.028948               | 0.000237               | 122.395161          | False                |
| 320            | 0.112784               | 0.000222               | 507.566524          | True                 |
| 480            | 0.266977               | 0.000200               | 1337.851852         | False                |
| 640            | 0.465314               | 0.000195               | 2382.987790         | True                 |
| 800            | 0.726081               | 0.000188               | 3854.943038         | False                |
| 960            | 1.033319               | 0.000195               | 5298.354523         | False                |
| 1120           | 1.398236               | 0.000185               | 7547.781210         | True                 |
| 1280           | 1.827499               | 0.000189               | 9665.936948         | False                |
| 1440           | 2.316721               | 0.000187               | 12394.174745        | True                 |
| 1600           | 3.965623               | 0.000188               | 21107.904822        | False                |

Из таблицы видно, что с увеличением размера данных время выполнения на CPU значительно возрастает, а время выполнения на GPU остаётся практически одинаковым независимо от размера данных. Ускорение растёт экспоненциально с увеличением размера данных, что подтверждает эффективность использования GPU для больших массивов. Результаты на CPU и GPU не всегда совпадают, что можно объяснить тем, что на GPU вычисления выполняются параллельно, что может привести к различиям в порядке выполнения и, как следствие, к небольшим погрешностям в результатах.

Ниже приведены графики зависимости времени выполнения программы от рамерности, а также график ускорения GPU относительно CPU.
![image](https://github.com/user-attachments/assets/24beb1b8-666f-4128-b2a2-af003326f5de)
![image](https://github.com/user-attachments/assets/f68d6009-22d0-42b7-ac63-929ee69d0d72)
![image](https://github.com/user-attachments/assets/cb6a9d47-8581-4f0a-aa7c-fde726114721)



