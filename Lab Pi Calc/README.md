# Задание
### Расчёт числа Pi
**Задача:** реализовать алгоритм вычисления числа Pi методом Монте-Карло  
**Язык:** C++ или Python  
**Входные данные:** количество точек N  
**Выходные данные:** время выполнения и полученные числа Pi  

# Описание проделанной работы
Данная лабораторная работа была выполнена на языке Python в Google Collab.

В данной лабораторной работе параллельные вычисления значения числа Pi на центральном процессоре (CPU) и графическом процессоре (GPU) с использованием библиотеки Numba и ее подмодуля CUDA для работы с CUDA-ядрами. Эксперимент проводится на случайно сгенерированных данных в области (0, 0) - (1, 1), и результаты времени выполнения сравниваются между CPU и GPU для разного числа точек N. 

**CPU:** функция `monte_carlo_cpu` вычисляет число Pi методом Монте-Карло, где для заданного количества точек N генерируются случайные координаты x и y, проверяется попадание точки в единичный круг, и если точка внутри круга, счётчик увеличивается, далее по формуле `Pi=4⋅доля точек внутри круга`, рассчитывается приближённое значение Pi.

**GPU:** также генерируются случайные координаты x и y, в функции `monte_carlo_gpu_kernel` каждый поток обрабатывает одну точку, проверяя условие попадания в круг единичного радиуса, впараллельном выполнении используется количество потоков, приближённое к числу точек N, что позволяет обрабатывать все точки параллельно. Параметры CUDA (`threads_per_block` и `blocks_per_grid`) настраиваются так, чтобы покрыть всё количество точек.

# Анализ результатов эксперимента
Были проведены тесты для различного числа точек N. В таблице ниже представлены результаты эксперимента:
| Число точек (N) | Pi (CPU) | Время CPU (сек) | Pi (GPU) | Время GPU (сек) | Ускорение |
|-----------------|----------|-----------------|----------|-----------------|-----------|
| 1000            | 3.084000 | 0.001695        | 3.104000 | 0.003755        | 0.451521  |
| 2000            | 3.106000 | 0.002036        | 3.174000 | 0.001002        | 2.032604  |
| 3000            | 3.141333 | 0.002967        | 3.105333 | 0.000894        | 3.318133  |
| 4000            | 3.145000 | 0.004110        | 3.188000 | 0.001204        | 3.412592  |
| 5000            | 3.151200 | 0.004875        | 3.164800 | 0.001205        | 4.046102  |
| 6000            | 3.154667 | 0.005916        | 3.140667 | 0.001072        | 5.517456  |
| 7000            | 3.100000 | 0.006884        | 3.144000 | 0.001069        | 6.437904  |
| 8000            | 3.162000 | 0.008926        | 3.133500 | 0.001260        | 7.085541  |
| 9000            | 3.152000 | 0.008945        | 3.132000 | 0.001107        | 8.080982  |
| 10000           | 3.138400 | 0.009970        | 3.124800 | 0.001173        | 8.497866  |

Из таблицы видно, что время выполнения на CPU растёт линейно с увеличением количества точек, а время выполнения на GPU остаётся сравнительно стабильным и значительно меньше, чем на CPU, начиная с N = 2000. С увеличением количества точек 
N число Pi стабилизируется и становится ближе к ожидаемому значению. Ускорение выполнения на GPU относительно CPU заметно увеличивается с ростом N, что указывает на более эффективное использование параллелизма. При малых значениях N ускорение на GPU ниже единицы, что объясняется накладными расходами на передачу данных между CPU и GPU. 

GPU оказывается значительно эффективнее для вычислений с большим числом точек, поскольку параллельные вычисления позволяют ускорить обработку за счёт одновременной проверки большого количества точек.

Также ниже приведены графики зависимости времени выполнения программы от N, а также график ускорения GPU относительно CPU.
![image](https://github.com/user-attachments/assets/9bf26a2b-d929-4329-ac5e-284cb6d8be5c)
![image](https://github.com/user-attachments/assets/9af85142-39bd-48a2-a7ce-b3e1580e73f7)
![image](https://github.com/user-attachments/assets/f66410b8-ec3c-4709-90ca-ad1ff01afbe8)


